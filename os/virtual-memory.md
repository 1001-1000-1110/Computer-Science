## 연속 메모리 할당

프로세스에 연속적인 메모리 공간을 할당하는 방식

### 스와핑

사용되지 않는 프로세스를 임시로 보조기억 장치의 스왑 영역으로 쫓아내고 메모리 상의 빈 공간에 다른 프로세스를 적재하여 실행하는 방식

- 스왑영역 : 프로세스들이 쫓겨나는 보조기억장치의 일부 영역
    
    보조기억장치에 저장되어있는 프로그램과는 별개로 존재하며, 보조 기억장치와 메모리간의 중간 저장소 역할을 한다.
    
- 스왑 아웃 : 현재 사용되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것
- 스왑 인 : 스왑 영역에 있던 프로세스가 다시 메모리고 옮겨오는 것

→ 스와핑을 이용하면 프로세스들의 총 크기가 메모리 크기보다 큰 경우에도 swap in/swap out을 반복하며 프로세스들을 동시에 실행할 수 있게된다.

### 메모리 할당

비어있는 메모리 공간에 프로세스를 연속적으로 할당하는 방식

1. 최초적합
    
    운영체제가 메모리 내의 빈 공간을 순서대로 검색하다가 적재할 수 있는 공간을 발견하면 그 공간에 프로세스를 배치하는 방식
    
2. 최적적합
    
    운영체제가 빈 공간을 모두 검색해본 후, 프로세스가 적재될 수 있는 공간 중 가장 작은 공간에 프로세스를 배치하는 방식
    
3. 최악적합
    
    운영체제가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 큰 공간에 프로세스를 배치하는 방식
    

### 외부 단편화

빈공간의 총합이 50MB일지라도 어느 빈공간에도 50MB크기의 프로세스가 적재될 수 없다.

프로세스를 할당하기 어려울 만큼 작은 메모리 공간들로 인해 메모리가 낭비되는 현상을 의미하며, 연속 메모리 할당은 이러한 외부 단편화라는 문제를 내포한다.

- 외부 단편화를 해결할 수 있는 대표적인 방안 : 압축
    
    빈공간들을 하나로 모으는 방식으로 작은 빈 공간들을 하나의 큰 빈 공간으로 만드는 방법
    
    → 작은 빈 공간들을 모으는 동안 시스템은 하던 일을 중지해야하고 메모리에 있는 내용을 옮기는 작업은 많은 오버헤드를 야기하며 오버헤드를 최소화하며 압출할 수 있는 지에 대한 명확한 방법을 결정하기 어렵다
    

## 페이징을 통한 가상 메모리 관리

연속 메모리 할당 방식의 두 가지 문제점

1. 외부단편화
2. 물리 메모리보다 큰 프로세스를 적재 불가능

→ 가상메모리 : 실행하고자 하는 프로그램을 일부만 메모리에 적재하여 실제 물리 메모리크기보다 더 큰 프로세스를 실핼할 수 있게 하는 기술

대표적인 가상 메모리 관리 기법 : 페이징, 세그멘테이션

### 페이징

메모리와 프로세스를 일정한 단위로 자르고, 이를 메모리에 불연속적으로 할당하는 방법 (페이지 → 프레임)

- 페이지 : 프로세스의 논리 주소 공간을 일정한 단위로 자른 것
- 프레임 : 메모리의 물리적인 주소 공간을 페이지와 동일한 크기의 일정한 단위로 자른 것

페이징에서는 페이지 단위로 스와핑을 사용할 수 있다.

메모리에 적재될 필요가 없는 페이지들은 보조기억장치에 스왑 아웃(페이지 아웃)되고, 실행에 필요한 페이지들은 메모리로 스왑 인(페이지 인) 된다. 이러한 방식으로 실제 메모리 크기보다 더 큰 프로세스를 실행할 수 있게된다

모든 페이지가 메모리에 적재될 필요가 없다 = 프로세스 전체가 메모리가 적재되지 않아도 된다

### 페이지 테이블

페이지 번호와 프레임 번호를 짝지어 주는 이정표로, CPU로 하여금 페이지 번호(논리주소)만 보고 해당 페이지가 적재된 프레임(물리주소)을 찾을 수 있게 한다. 즉, 물리 주소상에서는 프로세스들이 분산되어 저장되어 있더라도 CPU입장에서 바라본 논리 주소를 연속적으로 보일 수 있다. 프로세스마다 각자의 페이지 테이블을 갖으며 페이지 테이블들은 메모리게 적재되어 있다.

> **내부 단편화**
> 
> 
> 프로세스의 크기가 페이지 크기의 배수가 아닐 경우 빈공간이 발생으로 인한 메모리 낭비
> 
- PTBR(Page Table Base Register) in CPU
    
    각 프로세스의 페이지 테이블이 적재된 주소를 가르킨다. 
    
    각 프로세스의 페이지 테이블 정보는 PCB에 기록되며 문맥교환 시 레지스터에 변경되어 저장된다.
    
    < 문제점 >
    
    메모리 접근 시간이 두 배로 늘어난다.
    
    1. 메모리에 있는 페이지 테이블에 접근
    2. 테이블에서 알게된 프레임에 접근
- TLB(Translation Lookaside Buffer) in MMU
    
    페이지 테이블의 캐시메모리로, 참조 지역성에 근거해 페이지 테이블의 일부 내용을 저장
    
    - TLB hit
        
        CPU가 발생한 논리 주소에 대한 페이지 번호가 TLB에 있을 경우
        
        → 한 번의 메모리 접근
        
    - TLB miss
        
        CPU가 발생한 논리 주소에 대한 페이지 번호가 TLB에 없을 경우
        
        → 두 번의 메모리 접근
        

### 페이징에서의 주소 변환

페이징 시스템에서는 모든 논리 주소가 기본적으로 페이지 번호와 변위로 이루어져 있다.

- 페이지 테이블에서 해당 페이지 번호를 찾으면 페이지가 어떤 프레임에 할당되었는지를 알 수 있다.
- 논리주소 <페이지번호, 변위> ↔ 물리주소 <프레임번호, 변위>
    
    논리 주소의 변위과 물리주소의 변위 값은 같다
    
    ex) CPU가 논리주소 <5, 2>에 접근하고 싶고 페이지 번호 5번에 해당하는 프레임 번호가 3번이며 해당 프레임이 8번지부터 시작한다면 → CPU는 물리주소 10번지에 접근
    

### 페이지 테이블 엔트리 (PTE)

페이지 테이블의 각각의 행들

엔트리에 담기는 정보 : 페이지 번호, 프레임 번호, 유효비트, 보호 비트, 참조비트, 수정 비트

1. 유효비트
    
    현재 페이지가 메모리에 적재되어 있는지 아니면 보조기억장치에 있는지를 알려주는 비트
    
    - 0 : 메모리에 적재되어 있지 않음
    - 1 : 메모리에 적재되어 있음
  
  ❓ **Page fault**
    
    CPU가 유효 비트가 0인 페이지에 접근하려고 할 때 발생하는 예외(인터럽트)
    
    1. CPU는 기존의 작업을 백업
    2. 페이지 폴트 처리 루틴을 실행
    3. 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경
    
2. 보호비트
    
    페이지 보호 기능을 위해 존재하는 비트
    
    - 0 :  읽기만 가능
    - 1 : 읽고 쓰기 가능
    - r : read, w : write, x : execute
3. 참조비트
    
    CPU가 해당 페이지에 접근한 적이 있는지 여부
    
    - 1 : 적재 이후 CPU가 읽거나 쓴 페이지
    - 0 : 적재 이후 한번도 읽거나 쓴 적이 없는 페이지
4. 수정비트
    
    해당 페이지에 데이터를 쓴 적이 있는지 없는지 수정 여부(더티비트)
    
    - 1 : 변경된 적이 있는 페이지
    - 0 : 변경된 적이 없는 페이지
    
    ❓ **수정비트 존재 이유**
    
    페이지가 메모리에서 사라질 때(스왑아웃) 보조 기억장치에 쓰기 작업을 해야하는 지, 할 필요가 없는지를 판단하기 위해 존재
    
    - 0일 경우 : 추가 작업 없이 스왑 아웃
    - 1일 경우 : 변경된 값으로 보조기억장치에 수정 후 스왑 아웃
    

### Copy on write

fork 시스템 호출을 하면 부모 프로세스의 복사본이 자식 프로세스로서 만들어진다.(프로세스간의 자원 공유 X)

→ 프로세스 생성 시간을 늦출 뿐만 아니라 불필요한 메모리 낭비를 야기

copy on write의 경우, 자식 프로세스로 하여금 부모 프로세스의 동일한 프레임을 가리킨다. 이 후, 부모프로세스 혹은 자식 프로세스 둘 중 하나가 페이지에 쓰기 작업을 하면 그 순간 해당 페이지가 별도의 공간으로 복제된다. 

→ 프로세스 생성 시간을 줄여주고 메모리 공간도 절약

### Hierarchical paging

프로세스를 이루는 모든 페이지 테이블 엔트리를 할상 메모리에 유지하지 않을 수 있는 방법으로, 페이지 테이블을 페이징하여 여러 단계의 페이지를 두는 방식

필요한 페이지 테이블만 메모리에 적재하고 추후 해당 페이지 테이블을 참조해야할 경우 그때 메모리에 적재한다. (다만 Outer페이지 테이블은 항상 메모리에 유지해야함)

- 계층적 페이징일 경우의 논리주소
    
    → 페이지 테이블 계층은 여러개의 계층으로 구성될 수 있는데, 페이지 폴트가 발생했을 경우 메모리 참조 횟수가 많아지므로 계층이 많다고해서 반드시 좋다고 볼 수는 없다.
    

## 페이지 교체와 프레임 할당

1. 기존에 메모리에 적재된 불필요한 페이지를 선별하여 보조기억장치로 내보낼 수 있어야한다
    
    → 페이지 교체 알고리즘
    
2. 프로세스들에 적절한 수의 프레임을 할당하여 페이지를 할당할 수 있게 해야한다
    
    → 프레임 할당
    

### 요구페이징

모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 기법

1. CPU가 특정 페이지에 접근하는 명령어 실행
2. 유효비트가 1일 경우 CPU는 페이지가 적재된 프레임에 접근
3. 유효비트가 2일 경우 페이지 폴트 발생
4. 해당 페이지를 메모리로 적재하고 유효비트를 1로 설정
5. 1번 부터 수행

> **순수 요구 페이징**
> 
> 아무런 페이지도 메모리에 적재하지 않은 상태에서 무작정 실행하는 기법
> 

→ 요구페이징 시스템이 안정적으로 작동하려면 `페이지 교체`와 `프레임 할당`을 해결해야한다.

### 페이지 교체 알고리즘

요구페이징 기법으로 페이지들을 적재하다보면 언젠가는 메모리가 가득 차게 되는데 새로운 페이지를 적재하기 위해서는 기존의 페이지를 swap out해야한다. 이때, 어떤 페이지를 선택할지 결정하는 알고리즘이 페이지 교체 알고리즘이다.

좋은 페이지 교체 알고리즘이란? 페이지 폴트를 가장 적게 일으키는 알고리즘

- 페이지 폴트 횟수 : 페이지 폴트가 발생한 횟수
- 페이지 참조열 : CPU가 참조하는 페이지들 중 연속된 페이지를 생략한 페이지열
    
    중복된 페이지를 참조하는 행위는 페이지 폴트를 발생시키지 않음
    
    ### 1. FIFO 페이지 교체 알고리즘 (First In First Out)
    
    메모리에서 가장 먼저 올라온 페이지부터 내쫓는 방식 → 오래 머물렀다면 나가라
    
    < 단점 >
    
    해당 페이지가 프로그램 실행 내내 사용될 내용을 포함하고 있을 수도 있음
    
    - 2차 기회 페이지 교체 알고리즘
        
        FIFO와 마찬가지로 메모리에서 가장 오래 머물렀던 페이지를 대상으로 내보낼 페이지를 선별하지만 추가적으로
        
        - 만일 참조비트가 1이라면 당장 내쫓지 않고 참조 비트를 0으로 만든 뒤 현재 시간을 적재 시간으로 설정한다.(한번더 기회를 준다)
        - 참조비트가 0일 경우, 이 페이지는 가장 오래된 페이지인 동시에 사용되지 않은 페이지라고 볼 수 있으므로 보조기억장치로 내보낸다.
    
    ### 2. 최적 페이지 교체 알고리즘
    
    CPU에 의해 참조되는 횟수를 고려하는 페이지 교체 알고리즘으로 앞으로의 사용 빈도가 가장 낮은 페이지를 교체한다.
    
    → 가장 낮은 페이지 폴트율을 보장하는 알고리즘으로, 실제 구현이 어렵고 다른 페이지 교체 알고리즘의 이론상 성능을 평가하기 위한 목적으로 사용된다.
    
    ### 3. LRU 페이지 교체 알고리즘 (Least Recently Used Page Replacement Algorithm)
    
    가장 오랫동안 사용되지 않는 페이지를 교체하는 알고리즘으로, 페이지마다 마지막으로 사용한 시간을 토대로 최근에 가장 사용이 적었던 페이지를 교체한다.
    

### 스래싱과 프레임 할당

프로세스가 사용할 수 있는 프레임 수가 적어도 페이지 폴트를 자주 발생한다. 페이지 폴트가 자주 발생하면 CPU가 페이지를 교체하는데에 너무 많은 시간을 쏟게되고 성능에 악영향을 초래한다.

- 스래싱 : 프로세스가 실제 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 CPU이용률이 낮아져 성능이 저해되는 문제
    
    동시에 실행되는 프로세스 수가 어느 정도 증가하면 CPU이용률이 높아지지만, 필요 이상으로 늘리면 각 프로세스들이 사용할 수 있는 프레임 수가 줄어들기 때문에 페이지 폴트가 빈번히 발생하고 CPU이용률이 떨어져 전체적인 성능이 저해된다.
    
    → 스래싱의 근본적인 원인 : 각 프로세스가 필요로하는 **최소한의 프레임수가 보장**되지 않음
    

### 정적 할당 방식

프로세스의 실행 과정을 교려하지 않고 단순한 프로세스의 크기와 물리 메모리 크기만을 고려한 방식

1. 균등 할당
    
    모든 프로세스에 균등하게 프레임을 제공하는 방식
    
    < 단점 >
    
    실행되는 프로세스들의 크기는 각기 다른데, 동일한 프레임 개수를 할당하는 것은 비합리적
    
2. 비례 할당
    
    프로세스의 크기에 비례하여 프레임을 제공하는 방식
    
    < 단점 >
    
    하나의 프로세스가 실제로 얼마나 많은 프레임이 필요할지는 결국 실행해봐야 아는 경우가 많음
    

### 동적 할당 방식

프로세스를 실행하는 과정에서 배분할 프레임을 결정하는 방식

1. 작업 집합 모델
    
    프로세스가 일정 시간 동안 참조한 페이지 집합(작업집합)을기억하여 빈번한 페이지 교체를 방지
    
    → 작업 집합의 크기만큼만 프레임을 할당하는 방식
    
    > **작업 집합 구하기**
    > 
    > 
    > ex) 시간 간격이 7이라면
    > 
    > - t1에서의 작업 집합은 {5,6,7}
    >     
2. 페이지 폴트 빈도
    
    페이지 폴트율에 상한선과 하한선을 정하고, 이 범위 안에서만 프레임을 할당하는 방식
